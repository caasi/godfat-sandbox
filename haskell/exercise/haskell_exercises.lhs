\documentclass[fleqn]{article}
%include polycode.fmt
%format . = "\cdot "
%format * = "\times "

\font\tenss=cmss10
\renewcommand{\ss}[1]{\hbox\bgroup\tenss #1\egroup}

\newcommand{\Ex}[1]{\paragraph{#1}}
\newcommand{\Sol}{\vskip2ex\noindent \textbf{Sol.} }
\newcommand{\reason}[1]{\quad\{\,\hbox{#1}\,\}}
\newcommand{\cata}[1]{(\kern-.18em[ #1 ]\kern-.18em)}

\begin{document}

\Ex{1.} Given the type definition:
\begin{code}
data Tree a = Tip a | Bin (Tree a) (Tree a)
     deriving Show
\end{code}
Define
\begin{code}
flatten :: Tree a -> [a]
\end{code}
that returns the tips of the tree from left to right.

\Sol The base functor of |Tree a| is
\[ \ss{F} (a, X) = a + X \times X. \]
Every \ss{F}-algebra of type $\ss{F}(a, b) \to b$ can be expressed as
$[g, f]$, where $f :: b \times b \to b$ and $g :: a \to b$. We can derive
the |foldt| operator as follows:
\begin{eqnarray*}
&      & h = \cata{g, f}\\
&\equiv& \reason{catamorphisms}\\
&      & h \cdot \alpha = [g, f] \cdot \ss{F}(|id|, h)\\
&\equiv& \reason{expanding $\alpha$ and \ss{F}}\\
&      & h \cdot [|Tip|, |Bin|] = [g, f] \cdot (|id| + h \times h)\\
&\equiv& \reason{fusion of coproducts; coproduct functor}\\
&      & [h \cdot |Tip|, h \cdot |Bin|] = [g, f \cdot (h \times h)]\\
&\equiv& \reason{coproducts}\\
&      & h \cdot |Tip| = g \ \wedge\ 
         h \cdot |Bin| = f \cdot (h \times h).
\end{eqnarray*}
Translated to Haskell, it reads:
\begin{code}
foldt                ::  (b -> b -> b) -> (a -> b) -> Tree a -> b
foldt f g (Tip x)    =   g x
foldt f g (Bin t u)  =   f (foldt f g t) (foldt f g u)
\end{code}
With the |foldt| operator, it is now easy to define |flatten|.
\begin{code}
flatten = foldt (++) wrap
          where wrap x = [x]
\end{code}

\Ex{2.} What is the time complexity of the function |flatten|
you have defined? If it is not linear, can you derive a linear
variant of flatten, starting from this definition:
\begin{code}
fastflatten :: Tree a -> [a] -> [a]
-- ...
\end{code}

\Sol The time complexity of |flatten| is $\Theta(n^2)$
(in the worst case), where $n$ is the number of |Tip| nodes  in the tree.
\begin{enumerate}
\item |flatten| runs in time $O(n^2)$. A simple observation shows that
there are exactly $n - 1$ |Bin| nodes (which can be easily proven
by induction, or if you like, fold fusion), and |flatten| can take
$O(n)$ time for each |Bin| node, which is loosely estimated.
Thus the overall time complexity is
\[ (n - 1) \times O(n) = O(n^2). \]
\item There exists a set of trees that takes $\Theta(n^2)$ time to be
|flatten|ed, which can be generated by
\begin{code}
worst    ::  Int -> Tree ()
worst 1  =   Tip ()
worst n  =   Bin (worst (n - 1)) (Tip ())
\end{code}
The time complexity of |flatten| running on this particular set of cases is
\[ T(n) = T(n-1) + \Theta(n), \]
which is obviously $\Theta(n^2)$.
\end{enumerate}

It is possible to derive a faster version of |flatten| by fold-fusion,
using the idea of \textsl{accumulating parameters}. Our goal is to invent
a linear-time function |fastflatten| that satisfies
\[ |fastflatten t ys| = |flatten t ++ ys|. \]
Taking |ys = []|, |fastflatten t []| computes |flatten t| since |[]| is the
unit of list concatenation. The defining equation above can be rewritten
in the ``pointless'' style (following the title of Jeremy Gibbons's
radix-sort paper):
\begin{eqnarray*}
&      & |fastflatten t ys| = |flatten t ++ ys|\\
&\equiv& \reason{treating |(++)| as an ordinary function}\\
&      & |fastflatten t ys| = |(++) (flatten t) ys|\\
&\equiv& \reason{extensionality}\\
&      & |fastflatten t| = |(++) (flatten t)|\\
&\equiv& \reason{introducing function composition}\\
&      & |fastflatten t| = |((++) . flatten) t|\\
&\equiv& \reason{extensionality}\\
&      & |fastflatten| = |(++) . flatten|
\end{eqnarray*}
This immediately suggests that we try to fuse |(++)| into |flatten|,
which is a fold. If the fusion succeeds, the resulting fold would be
|fastflatten|.

Let's go back for a moment to the \textsl{Algebra of Programming} to make
the fusion conditions right. The general fusion law states:
\[ h \cdot \cata{f} = \cata{g} \quad\Leftarrow\quad
   h \cdot f = g \cdot \ss{F}(|id|, h),\]
which for |Tree a| would specialise to
\[ h \cdot \cata{g, f} = \cata{g', f'} \quad\Leftarrow\quad
   h \cdot [g, f] = [g', f'] \cdot (|id| + h \times h),\]
which can in turn be translated into (nearly) Haskell notation:
\[ h \cdot |foldt f g| = |foldt f' g'| \quad\Leftarrow\quad
   |h . g| = |g'| \ \wedge\ |h (f x y)| = |f' (h x) (h y)|. \]
Thus in order to express |(++) . flatten| as a single fold,
we need to invent two functions $f'$ and $g'$ while at the same time
proving that:
\begin{eqnarray*}
|(++) . wrap| &=& |g'|,\\
|(++) (x ++ y)| &=& |f' (x ++) (y ++)|.
\end{eqnarray*}
It is easy to see that |g'| can be $(:)$, since its job is concatenating
a singleton list constructed from its argument to the front of some other
list. The inductive case is more interesting. Given two functions that
concatenate |x| and |y| to the front of some list respectively, how do we
accomplish the task of concatenating |x ++ y| to the front of some list?
Hey! That's applying the two functions in reverse argument order! Thus
$f'$ is simply function composition |(.)|. In order to gain more
confidence, let's do some formal reasoning for the inductive case, which
is done pointwisely:
\begin{eqnarray*}
& & |(++) (x ++ y) z|\\
&=& \reason{writing |(++)| as an infix operator}\\
& & |(x ++ y) ++ z|\\
&=& \reason{|++| is associative (aha, that's the key, right?)}\\
& & |x ++ (y ++ z)|\\
&=& \reason{partial application}\\
& & |(x ++) ((y ++) z)|\\
&=& \reason{function composition (functional form)}\\
& & |(.) (x ++) (y ++) z|
\end{eqnarray*}
Therefore by extensionality, we have |(++) (x ++ y) = (.) (x ++) (y ++)|.
We have thus derived |fastflatten = foldt (.) (:)|. This has an intuitive
meaning: transform the tips into functions that add a tip to the front of
some list, and then compose all the functions together. Equivalently we
have |fastflatten t ys = foldt (.) (:) t ys|, which expands to
\begin{code}
fastflatten (Tip x) ys = x : ys
fastflatten (Bin t u) ys = fastflatten t (fastflatten u ys)
\end{code}
It is the standard implementation with accumulating parameters,
which is in part tail-recursive and runs in linear time.

I figured out the derivation myself during a class. The beauty in the
derivation makes me believe that there must be some way to generalise
the result, and it is possible to discover the generalisation all by
myself. Unfortunately, the derivation is already recorded in section 3.5
of the \textsl{Algebra of Programming} (which is just the section that
I skipped!), and a generalisation is proposed in an exercise. Anyway,
it's still wonderful experience to carry out a beautiful derivation
by oneself.

\Ex{3.} Well, let's practice using some library functions\ldots
Recall that |[1..]| creates an infinite list starting from 1.
Define factorial using |[1..]|, |take|, and |foldr| (thus you
do not need recursion).
\Sol
\begin{code}
fact    ::  Int -> Int
fact n  =   foldr (*) 1 (take n [1..])
\end{code}

\Ex{4.1} Define a function
\begin{code}
sieve :: Int -> [Int] -> [Int]
\end{code}
such that |sieve n xs| removes elements in |xs| that are multiples of |n|.
You may either use recursion, use a |foldr|, or use the library function
|filter|. You will also need the built-in function``|mod|''.

\Sol
\begin{code}
sieve n = filter (isNotMultiple n)
          where isNotMultiple n x = x `mod` n /= 0
\end{code}

\Ex{4.2} Having |sieve|, define
\begin{code}
fix (x : xs) = x : sieve x (fix xs)
\end{code}
What does |fix [2..]| represent? In the GHCi or Hugs interpreter, how do you
examine the first 100 outputs of |fix [2..]|?

\Sol Let's expand the definition to
\[ |fix (x : xs) = x : filter (isNotMultiple x) (fix xs)|, \]
Haskell is a lazy functional language, which means its reduction
strategy is ``outermost graph reduction,'' if Richard Bird is right.
Let's try a few steps of the evaluation:
\begin{eqnarray*}
& & |fix [2..]| \\
&=& \reason{expanding |fix|} \\
& & |2 : filter (isNotMultiple 2) (fix [3..])| \\
&=& \reason{|filter| somehow tries to do pattern matching---expanding |fix|} \\
& & |2 : filter (isNotMultiple 2) (3 : filter (isNotMultiple 3) (fix [4..]))| \\
&=& \reason{$3$ is not a multiple of $2$} \\
& & |2 : 3 : filter (isNotMultiple 2) (filter (isNotMultiple 3) (fix [4..]))| \\
&=& \reason{the two |filter|s doing pattern matching---expanding |fix|} \\
& & |2 : 3 : filter (isNotMultiple 2) (filter (isNotMultiple 3) (4 : filter (isNotMultiple 4) (fix [5..])))| \\
&=& \reason{$4$ is not a multiple of $3$ but is a multiple of $2$} \\
& & |2 : 3 : filter (isNotMultiple 2) (filter (isNotMultiple 3) (filter (isNotMultiple 4) (fix [5..])))| \\
&=& \reason{keep going} \\
& & \ldots
\end{eqnarray*}
It is easy to see that a number $n > 2$ appears in the list |fix [2..]|
if and only if it passes through all the |filter|s ahead of it, i.e.,
it is not a multiple of $k$ for all $2 \leq k < n$, which is equivalent
to saying that $n$ is a prime number. Since $2$ is also in the list,
|fix [2..]| is the list of all prime numbers.

The first 100 numbers in the list can be examined by entering
\[ |take 100 (fix [2..])|. \]

\Ex{4.3} What about
\begin{code}
fix2 (x : xs) = x : fix2 (sieve x xs)
\end{code}
What does it represent? Which of |fix| and |fix2| is faster? Why?

\Sol Again, let's try a few evaluation steps of |fix2 [2..]|:
\begin{eqnarray*}
& & |fix2 [2..]| \\
&=& \reason{expanding |fix|} \\
& & |2 : fix2 (sieve 2 [3..])| \\
&=& \reason{|fix2| trying to pattern-match its argument---expanding |sieve|} \\
& & |2 : fix2 (filter (isNotMultiple 2) [3..])| \\
&=& \reason{evaluating |filter|} \\
& & |2 : fix2 (3 : filter (isNotMultiple 2) [4..])| \\
&=& \reason{expanding |fix2|} \\
& & |2 : 3 : fix2 (sieve 3 (filter (isNotMultiple 2) [4..]))| \\
&=& \reason{expanding |sieve|} \\
& & |2 : 3 : fix2 (filter (isNotMultiple 3) (filter (isNotMultiple 2) [4..]))| \\
&=& \reason{evaluating the inner |filter|---$4$ is a multiple of $2$} \\
& & |2 : 3 : fix2 (filter (isNotMultiple 3) (filter (isNotMultiple 2) [5..]))| \\
&=& \reason{evaluating the |filter|s and |fix2|} \\
& & |2 : 3 : 5 : fix2 (filter (isNotMultiple 5) (filter (isNotMultiple 3) (filter (isNotMultiple 2) [6..])))| \\
&=& \reason{keep going} \\
& & \ldots
\end{eqnarray*}
It suggests that a number $n > 2$ appears in the list |fix2 [2..]| if
and only if $n$ is not divisible by the prime numbers less than $n$.
Therefore it should be the case that |fix2 [2..]| is again the list of
prime numbers. For every number $n > 2$, |fix2| tests $n$ with
only the prime numbers less than $n$, while |fix| tests $n$ with all
$k$'s where $2 \leq k < n$. The \textsl{prime number theorem} states that
\[ \lim_{x \to \infty} \frac{\pi(x)}{x / \ln(x)} = 1, \]
where $\pi(x)$ is the number of primes less than or equal to $x$.
This entails that \[ \lim_{x \to \infty} \frac{\pi(x)}{x} = 0, \]
which means prime numbers are asymptotically very sparse (since the
density goes to zero), though it may not be very obvious when $x$
is not too large. So we can expect the speed ratio of |fix2| to |fix|
would increase as more terms are generated.

\Ex{4.4} In the interpreter, check whether |fix [2..]| yield the same
output for the first $100$, $200$, or $300$ outputs. You may find some
standard library function such as |zipWith|, |(==)|, |take|, and
``|and|'' useful. (``|and|'' is a function having type |[Bool] -> Bool|.
You can easily guess what it does\ldots)

\Sol One can directly type, say,
\[ |and (zipWith (==) (take 100 (fix [2..])) (take 100 (fix2 [2..])))| \]
in the interpreter to check the first 100 terms. Or one can define
\begin{code}
checkEqual f g n xs = and (zipWith (==) (take n (f xs)) (take n (g xs)))
\end{code}
Then |checkEqual fix fix2 n [2..]| would check whether |fix [2..]| and
|fix2 [2..]| yields the same result for the first $n$ terms.

It is possible to formally prove that $|fix [2..]| = |fix2 [2..]|$,
say by showing
\[ |approx n (fix [2..])| = |approx n (fix2 [2..])| \qquad
   \hbox{for all $n$,} \]
where |approx| is defined to be
\begin{code}
approx               ::  Integer -> [a] -> [a]
approx (n+1) []      =   []
approx (n+1) (x:xs)  =   x : approx n xs
\end{code}
as in Richard Bird's functional programming book. Then it follows that
\[ |fix [2..]| = \lim_{n \to \infty} |approx n (fix [2..])|
               = \lim_{n \to \infty} |approx n (fix2 [2..])|
	       = |fix2 [2..]|. \]
This approach utilises the \textsl{approximation lemma}.
However we omit the proof here for obvious reasons\ldots\ The other way
to establish the equality is to separately prove that |fix [2..]| and
|fix2 [2..]| both generate the list of prime numbers. Nevertheless
I guess the two approaches would turn out to be essentially the same.

\end{document}
